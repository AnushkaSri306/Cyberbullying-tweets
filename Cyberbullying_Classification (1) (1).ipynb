{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and gathering basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "Sl_Nt8JlQih0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "4QTFHTNQRXOC",
    "outputId": "ccaeb259-a17e-4f00-a313-26bae400698e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_text</td>\n",
       "      <td>cyberbullying_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                   1\n",
       "0                                         tweet_text  cyberbullying_type\n",
       "1  In other words #katandandre, your food was cra...   not_cyberbullying\n",
       "2  Why is #aussietv so white? #MKR #theblock #ImA...   not_cyberbullying"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('cyberbullying_tweets.XLS',header=None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "LMhA6UW_bO3c"
   },
   "outputs": [],
   "source": [
    "df.columns = df.iloc[0]\n",
    "df = df[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HS-XQg9zRlQl",
    "outputId": "bc5eb32a-4e42-42c7-a2f9-f0c9ccf683be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47692, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "yPZrioQjRq21",
    "outputId": "52bb181b-275d-4a7b-b45b-84c97693a1f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyberbullying_type\n",
       "religion               7998\n",
       "age                    7992\n",
       "gender                 7973\n",
       "ethnicity              7961\n",
       "not_cyberbullying      7945\n",
       "other_cyberbullying    7823\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cyberbullying_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "xTs7-8DZSTcL",
    "outputId": "ca5f7894-9a97-48fc-a0aa-f365af1a7964"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "tweet_text            0\n",
       "cyberbullying_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UaUnjCTpts_0",
    "outputId": "1eea0818-2f3a-4df2-a4cb-bfd5d89c2a93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>Our pancakes are selling like hotcakes Shaz - ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>But you all respect him....Pete hasn't read tw...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>This is the opportunity to prove ourselves lik...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>Strategicscoring should be classed as cheating...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>If we're at the bottom of the leaderboard, we'...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7227</th>\n",
       "      <td>It wouldn't be fair. Kat knows NOTHING of fair...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7278</th>\n",
       "      <td>@TVWEEKmag: There is only 1 way to stay in the...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>@Ima_TV_Junkie: What the hell were Annie and L...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9672</th>\n",
       "      <td>@victorymonk: #sorryitsaboy joke means more bo...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9835</th>\n",
       "      <td>@thisonesakillaa: In my opinion? All jokes are...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>Simple things please simple minds. @pumpkinkin...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12664</th>\n",
       "      <td>No offense. @NigelBigMeech I'm not sexist but ...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12695</th>\n",
       "      <td>raped is not a synonym for \"touched\" @magconbo...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12714</th>\n",
       "      <td>@Transic_nyc: What do u think her punishment s...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>girls @Dehner07 In usually not sexist, but gir...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12851</th>\n",
       "      <td>We've proven we're not just dumb blondes and p...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13396</th>\n",
       "      <td>We proved that we're not just pretty faces. Oh...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13830</th>\n",
       "      <td>@ErikssonMalin85: #QuestionsForMen ever walked...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>We want everyone to know we are not just prett...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13859</th>\n",
       "      <td>girl sports gives it away here @LM26_LYE_ERA I...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14102</th>\n",
       "      <td>Females and \"guys.\" @AwkwardEP I'm not sexist ...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14222</th>\n",
       "      <td>@nethercott_eden: Why is #WomenAgainstFeminism...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14235</th>\n",
       "      <td>I'm not sexist, except when I am. @gentlemanby...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>I'm not sexist, there are women everywhere! @d...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14516</th>\n",
       "      <td>Women's bathrooms are so much worse than men's...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14760</th>\n",
       "      <td>@ErikssonMalin85: Have u ever expressed ur ang...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15018</th>\n",
       "      <td>Radical? lol no @David_i_think Call me sexist....</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>@MHWitchfinder: Please, if you disagree with H...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>I'm not sexist, I just become instantly virule...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15572</th>\n",
       "      <td>@botticellicream: I'm curvy. The kind men fap ...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15839</th>\n",
       "      <td>We're not just the dumb blondes with the prett...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15849</th>\n",
       "      <td>just don't = the sum total of your unconscious...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15887</th>\n",
       "      <td>@fee_bee_63: Kat is a completely rank cow but ...</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>A Pakistani court has sentenced 86 members of ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46962</th>\n",
       "      <td>Still, Davis, who is gay, said he pays a socia...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47397</th>\n",
       "      <td>Racism won't stop as long as u stil select ur ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                             tweet_text cyberbullying_type\n",
       "1758   Our pancakes are selling like hotcakes Shaz - ...  not_cyberbullying\n",
       "3833   But you all respect him....Pete hasn't read tw...  not_cyberbullying\n",
       "3939   This is the opportunity to prove ourselves lik...  not_cyberbullying\n",
       "5684   Strategicscoring should be classed as cheating...  not_cyberbullying\n",
       "6975   If we're at the bottom of the leaderboard, we'...  not_cyberbullying\n",
       "7227   It wouldn't be fair. Kat knows NOTHING of fair...  not_cyberbullying\n",
       "7278   @TVWEEKmag: There is only 1 way to stay in the...  not_cyberbullying\n",
       "7822   @Ima_TV_Junkie: What the hell were Annie and L...  not_cyberbullying\n",
       "9672   @victorymonk: #sorryitsaboy joke means more bo...             gender\n",
       "9835   @thisonesakillaa: In my opinion? All jokes are...             gender\n",
       "11076  Simple things please simple minds. @pumpkinkin...             gender\n",
       "12664  No offense. @NigelBigMeech I'm not sexist but ...             gender\n",
       "12695  raped is not a synonym for \"touched\" @magconbo...             gender\n",
       "12714  @Transic_nyc: What do u think her punishment s...             gender\n",
       "12789  girls @Dehner07 In usually not sexist, but gir...             gender\n",
       "12851  We've proven we're not just dumb blondes and p...             gender\n",
       "13396  We proved that we're not just pretty faces. Oh...             gender\n",
       "13830  @ErikssonMalin85: #QuestionsForMen ever walked...             gender\n",
       "13839  We want everyone to know we are not just prett...             gender\n",
       "13859  girl sports gives it away here @LM26_LYE_ERA I...             gender\n",
       "14102  Females and \"guys.\" @AwkwardEP I'm not sexist ...             gender\n",
       "14222  @nethercott_eden: Why is #WomenAgainstFeminism...             gender\n",
       "14235  I'm not sexist, except when I am. @gentlemanby...             gender\n",
       "14286  I'm not sexist, there are women everywhere! @d...             gender\n",
       "14516  Women's bathrooms are so much worse than men's...             gender\n",
       "14760  @ErikssonMalin85: Have u ever expressed ur ang...             gender\n",
       "15018  Radical? lol no @David_i_think Call me sexist....             gender\n",
       "15420  @MHWitchfinder: Please, if you disagree with H...             gender\n",
       "15422  I'm not sexist, I just become instantly virule...             gender\n",
       "15572  @botticellicream: I'm curvy. The kind men fap ...             gender\n",
       "15839  We're not just the dumb blondes with the prett...             gender\n",
       "15849  just don't = the sum total of your unconscious...             gender\n",
       "15887  @fee_bee_63: Kat is a completely rank cow but ...             gender\n",
       "20604  A Pakistani court has sentenced 86 members of ...           religion\n",
       "46962  Still, Davis, who is gay, said he pays a socia...          ethnicity\n",
       "47397  Racism won't stop as long as u stil select ur ...          ethnicity"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "Bh_ZcBBKttC7"
   },
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K11dPpjnttGZ",
    "outputId": "1f4f35cf-d9fb-402d-872d-ce35d1a54807"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering info about hashtags and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HARDA7S92n9s",
    "outputId": "e5d76787-43ab-4f32-9267-6d2e99925727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hashtags in dataset: 11222\n",
      "Total number of mentions in dataset: 26981\n",
      "0                                         tweet_text  num_hashtags  \\\n",
      "0  In other words #katandandre, your food was cra...             2   \n",
      "1  Why is #aussietv so white? #MKR #theblock #ImA...            10   \n",
      "2  @XochitlSuckkks a classy whore? Or more red ve...             0   \n",
      "3  @Jason_Gio meh. :P  thanks for the heads up, b...             0   \n",
      "4  @RudhoeEnglish This is an ISIS account pretend...             0   \n",
      "\n",
      "0  num_mentions  \n",
      "0             0  \n",
      "1             0  \n",
      "2             1  \n",
      "3             1  \n",
      "4             1  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Check if 'tweet_text' column exists\n",
    "if 'tweet_text' in df.columns:\n",
    "    # Count hashtags per tweet\n",
    "    df['num_hashtags'] = df['tweet_text'].apply(lambda x: len(re.findall(r'#\\w+', str(x))))\n",
    "\n",
    "    # Count mentions per tweet\n",
    "    df['num_mentions'] = df['tweet_text'].apply(lambda x: len(re.findall(r'@\\w+', str(x))))\n",
    "\n",
    "    # Calculate total counts\n",
    "    total_hashtags = df['num_hashtags'].sum()\n",
    "    total_mentions = df['num_mentions'].sum()\n",
    "\n",
    "    print(f\"Total number of hashtags in dataset: {total_hashtags}\")\n",
    "    print(f\"Total number of mentions in dataset: {total_mentions}\")\n",
    "\n",
    "    # Display sample rows with counts\n",
    "    print(df[['tweet_text', 'num_hashtags', 'num_mentions']].head(5))\n",
    "else:\n",
    "    print(\"Column 'tweet_text' not found in the dataset. Please verify the column name.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aH7CMkkr3C7c",
    "outputId": "b3b9bad7-1f14-4cfc-c0e8-745fdd9b35a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11222\n"
     ]
    }
   ],
   "source": [
    "# finding all hashtags\n",
    "if 'tweet_text' in df.columns:\n",
    "  df['hashtags']=df['tweet_text'].apply(lambda x: len(re.findall(r'#\\w+',str(x))))\n",
    "  total_hashtags=(df['hashtags'].sum())\n",
    "  print(total_hashtags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@Raja5aab @Quickieleaks Yes, the test of god i...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Itu sekolah ya bukan tempat bully! Ga jauh kay...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Karma. I hope it bites Kat on the butt. She is...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@stockputout everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rebecca Black Drops Out of School Due to Bully...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "5  @Raja5aab @Quickieleaks Yes, the test of god i...  not_cyberbullying   \n",
       "6  Itu sekolah ya bukan tempat bully! Ga jauh kay...  not_cyberbullying   \n",
       "7  Karma. I hope it bites Kat on the butt. She is...  not_cyberbullying   \n",
       "8       @stockputout everything but mostly my priest  not_cyberbullying   \n",
       "9  Rebecca Black Drops Out of School Due to Bully...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  hashtags  \n",
       "0             2             0         2  \n",
       "1            10             0        10  \n",
       "2             0             1         0  \n",
       "3             0             1         0  \n",
       "4             0             1         0  \n",
       "5             0             2         0  \n",
       "6             0             0         0  \n",
       "7             1             0         1  \n",
       "8             0             1         0  \n",
       "9             0             0         0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbVDM_pK3-Wx",
    "outputId": "2b4f27fe-e4da-422e-e869-7fc93b67127e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most frequently used hashtags:\n",
      "           Hashtag  Count\n",
      "0             #MKR   1312\n",
      "1             #mkr   1186\n",
      "2           #Islam    145\n",
      "3  #BlameOneNotAll    117\n",
      "4       #notsexist    104\n",
      "5            #ISIS     94\n",
      "6         #MKR2015     85\n",
      "7            #coon     75\n",
      "8      #MileyCyrus     68\n",
      "9         #mkr2015     65\n"
     ]
    }
   ],
   "source": [
    "# most used hashtags\n",
    "from collections import Counter\n",
    "\n",
    "# Check if 'tweet_text' column exists\n",
    "if 'tweet_text' in df.columns:\n",
    "    # Extract all hashtags from the dataset\n",
    "    all_hashtags = df['tweet_text'].apply(lambda x: re.findall(r'#\\w+', str(x))).sum()\n",
    "\n",
    "    # Count frequency of each hashtag\n",
    "    hashtag_counts = Counter(all_hashtags)\n",
    "\n",
    "    # Convert to a DataFrame for better readability\n",
    "    hashtag_df = pd.DataFrame(hashtag_counts.items(), columns=['Hashtag', 'Count'])\n",
    "    hashtag_df = hashtag_df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"Top 10 most frequently used hashtags:\")\n",
    "    print(hashtag_df.head(10))\n",
    "else:\n",
    "    print(\"Column 'tweet_text' not found in the dataset. Please verify the column name.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "N34Y8RFa5Knc",
    "outputId": "d430f71d-4917-46b4-d85b-53504e197ea1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  hashtags  \n",
       "0             2             0         2  \n",
       "1            10             0        10  \n",
       "2             0             1         0  \n",
       "3             0             1         0  \n",
       "4             0             1         0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_Vz-ROt5RDr",
    "outputId": "cf610c90-9927-4d87-aedb-694600c614cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_text', 'cyberbullying_type', 'num_hashtags', 'num_mentions',\n",
       "       'hashtags'],\n",
       "      dtype='object', name=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWLyJuHLWp8A",
    "outputId": "8a608308-d641-4bb5-bc3b-8a008f156945"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_125564\\4068232756.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df=df.applymap(lambda x:x.lower() if isinstance(x,str)else x)\n"
     ]
    }
   ],
   "source": [
    "# converting text to lowercase\n",
    "df=df.applymap(lambda x:x.lower() if isinstance(x,str)else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgMQ2fvm6p_X",
    "outputId": "0eb3b0d7-3575-4d61-d95b-b9e19cd0075d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cyberbullying_type hashtags  count\n",
      "426                   age  #sffpit     18\n",
      "1112            ethnicity  #racism     36\n",
      "1976               gender     #mkr    628\n",
      "2991    not_cyberbullying     #mkr   1594\n",
      "3865  other_cyberbullying     #mkr    285\n",
      "4607             religion   #islam    131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Extract hashtags from the 'tweet_text' column using a regular expression\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r'#\\w+', text)\n",
    "\n",
    "df['hashtags'] = df['tweet_text'].apply(extract_hashtags)\n",
    "\n",
    "# Step 2: Explode the 'hashtags' column to have each hashtag in its own row\n",
    "df_exploded = df.explode('hashtags')\n",
    "\n",
    "# Step 3: Remove any rows where hashtags are missing (if any)\n",
    "df_exploded = df_exploded[df_exploded['hashtags'].notna()]\n",
    "\n",
    "# Step 4: Group by 'cyberbullying_type' and 'hashtags' to count occurrences\n",
    "hashtag_counts = df_exploded.groupby(['cyberbullying_type', 'hashtags']).size().reset_index(name='count')\n",
    "\n",
    "# Step 5: Find the most frequent hashtag for each 'cyberbullying_type'\n",
    "most_used_hashtags = hashtag_counts.loc[hashtag_counts.groupby('cyberbullying_type')['count'].idxmax()]\n",
    "\n",
    "# Step 6: Display the results\n",
    "print(most_used_hashtags[['cyberbullying_type', 'hashtags', 'count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pU8cLCU364eq",
    "outputId": "15742e36-458d-4c7f-e6d7-c3815445f334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        cyberbullying_type          mentions  count\n",
      "301                    age  @realdonaldtrump     15\n",
      "3231             ethnicity        @tayyoung_    959\n",
      "5646                gender            @mt8_9     89\n",
      "8016     not_cyberbullying      @freebsdgirl     75\n",
      "11597  other_cyberbullying      @freebsdgirl    151\n",
      "14741             religion    @maxblumenthal    119\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Extract mentions (usernames starting with '@') from the 'tweet_text' column using a regular expression\n",
    "def extract_mentions(text):\n",
    "    return re.findall(r'@\\w+', text)\n",
    "\n",
    "df['mentions'] = df['tweet_text'].apply(extract_mentions)\n",
    "\n",
    "# Step 2: Explode the 'mentions' column to have each mention in its own row\n",
    "df_exploded_mentions = df.explode('mentions')\n",
    "\n",
    "# Step 3: Remove any rows where mentions are missing (if any)\n",
    "df_exploded_mentions = df_exploded_mentions[df_exploded_mentions['mentions'].notna()]\n",
    "\n",
    "# Step 4: Group by 'cyberbullying_type' and 'mentions' to count occurrences\n",
    "mention_counts = df_exploded_mentions.groupby(['cyberbullying_type', 'mentions']).size().reset_index(name='count')\n",
    "\n",
    "# Step 5: Find the most frequent mention for each 'cyberbullying_type'\n",
    "most_used_mentions = mention_counts.loc[mention_counts.groupby('cyberbullying_type')['count'].idxmax()]\n",
    "\n",
    "# Step 6: Display the results\n",
    "print(most_used_mentions[['cyberbullying_type', 'mentions', 'count']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "WnFNcZAxY5Fh",
    "outputId": "482eec3b-671c-4da8-efea-b9cdc434928d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jason_gio meh. :p  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jason_gio]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rudhoeenglish this is an isis account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@rudhoeenglish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@raja5aab @quickieleaks yes, the test of god i...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@raja5aab, @quickieleaks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>itu sekolah ya bukan tempat bully! ga jauh kay...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>karma. i hope it bites kat on the butt. she is...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[#mkr]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@stockputout everything but mostly my priest</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@stockputout]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rebecca black drops out of school due to bully...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "3  @jason_gio meh. :p  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @rudhoeenglish this is an isis account pretend...  not_cyberbullying   \n",
       "5  @raja5aab @quickieleaks yes, the test of god i...  not_cyberbullying   \n",
       "6  itu sekolah ya bukan tempat bully! ga jauh kay...  not_cyberbullying   \n",
       "7  karma. i hope it bites kat on the butt. she is...  not_cyberbullying   \n",
       "8       @stockputout everything but mostly my priest  not_cyberbullying   \n",
       "9  rebecca black drops out of school due to bully...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "3             0             1   \n",
       "4             0             1   \n",
       "5             0             2   \n",
       "6             0             0   \n",
       "7             1             0   \n",
       "8             0             1   \n",
       "9             0             0   \n",
       "\n",
       "0                                           hashtags  \\\n",
       "0                               [#katandandre, #mkr]   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "5                                                 []   \n",
       "6                                                 []   \n",
       "7                                             [#mkr]   \n",
       "8                                                 []   \n",
       "9                                                 []   \n",
       "\n",
       "0                    mentions  \n",
       "0                          []  \n",
       "1                          []  \n",
       "2           [@xochitlsuckkks]  \n",
       "3                [@jason_gio]  \n",
       "4            [@rudhoeenglish]  \n",
       "5  [@raja5aab, @quickieleaks]  \n",
       "6                          []  \n",
       "7                          []  \n",
       "8              [@stockputout]  \n",
       "9                          []  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KOKjSqK06L_",
    "outputId": "04dcfa92-e3d6-4190-ba5c-ba4e7ffd87e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\anush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "lRHobgtdCoxi",
    "outputId": "3b061833-820e-407c-ecfb-7058a3c16fae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jason_gio meh. :p  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jason_gio]</td>\n",
       "      <td>[@jason_gio meh., :p  thanks for the heads up,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rudhoeenglish this is an isis account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@rudhoeenglish]</td>\n",
       "      <td>[@rudhoeenglish this is an isis account preten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[black ppl aren't expected to do anything, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment. tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[turner did not withhold his disappointment., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i swear to god., this dumb nigger bitch., i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt @therealexel: if youre a nigge...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@therealexel]</td>\n",
       "      <td>[yea fuck you rt @therealexel: if youre a nigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro. u gotta chill rt @chillshrammy: dog fuck ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@chillshrammy]</td>\n",
       "      <td>[bro., u gotta chill rt @chillshrammy: dog fuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47656 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                             tweet_text cyberbullying_type  \\\n",
       "0      in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1      why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2      @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "3      @jason_gio meh. :p  thanks for the heads up, b...  not_cyberbullying   \n",
       "4      @rudhoeenglish this is an isis account pretend...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  black ppl aren't expected to do anything, depe...          ethnicity   \n",
       "47688  turner did not withhold his disappointment. tu...          ethnicity   \n",
       "47689  i swear to god. this dumb nigger bitch. i have...          ethnicity   \n",
       "47690  yea fuck you rt @therealexel: if youre a nigge...          ethnicity   \n",
       "47691  bro. u gotta chill rt @chillshrammy: dog fuck ...          ethnicity   \n",
       "\n",
       "0      num_hashtags  num_mentions  \\\n",
       "0                 2             0   \n",
       "1                10             0   \n",
       "2                 0             1   \n",
       "3                 0             1   \n",
       "4                 0             1   \n",
       "...             ...           ...   \n",
       "47687             0             0   \n",
       "47688             0             0   \n",
       "47689             0             0   \n",
       "47690             0             1   \n",
       "47691             0             1   \n",
       "\n",
       "0                                               hashtags           mentions  \\\n",
       "0                                   [#katandandre, #mkr]                 []   \n",
       "1      [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                     []  [@xochitlsuckkks]   \n",
       "3                                                     []       [@jason_gio]   \n",
       "4                                                     []   [@rudhoeenglish]   \n",
       "...                                                  ...                ...   \n",
       "47687                                                 []                 []   \n",
       "47688                                                 []                 []   \n",
       "47689                                                 []                 []   \n",
       "47690                                                 []     [@therealexel]   \n",
       "47691                                                 []    [@chillshrammy]   \n",
       "\n",
       "0                                              sentences  \n",
       "0      [in other words #katandandre, your food was cr...  \n",
       "1      [why is #aussietv so white?, #mkr #theblock #i...  \n",
       "2      [@xochitlsuckkks a classy whore?, or more red ...  \n",
       "3      [@jason_gio meh., :p  thanks for the heads up,...  \n",
       "4      [@rudhoeenglish this is an isis account preten...  \n",
       "...                                                  ...  \n",
       "47687  [black ppl aren't expected to do anything, dep...  \n",
       "47688  [turner did not withhold his disappointment., ...  \n",
       "47689  [i swear to god., this dumb nigger bitch., i h...  \n",
       "47690  [yea fuck you rt @therealexel: if youre a nigg...  \n",
       "47691  [bro., u gotta chill rt @chillshrammy: dog fuc...  \n",
       "\n",
       "[47656 rows x 7 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "df['sentences'] = df['tweet_text'].apply(lambda text: sent_tokenize(text) if isinstance(text, str) else [])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "sYAKkMpRmc5d",
    "outputId": "1ca74610-b4ad-4c51-dea3-7b8f9db5d91f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jason_gio meh. :p  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@jason_gio]</td>\n",
       "      <td>[@jason_gio meh., :p  thanks for the heads up,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@rudhoeenglish this is an isis account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@rudhoeenglish]</td>\n",
       "      <td>[@rudhoeenglish this is an isis account preten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[black ppl aren't expected to do anything, dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>turner did not withhold his disappointment. tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[turner did not withhold his disappointment., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i swear to god., this dumb nigger bitch., i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt @therealexel: if youre a nigge...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@therealexel]</td>\n",
       "      <td>[yea fuck you rt @therealexel: if youre a nigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro. u gotta chill rt @chillshrammy: dog fuck ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@chillshrammy]</td>\n",
       "      <td>[bro., u gotta chill rt @chillshrammy: dog fuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47656 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                             tweet_text cyberbullying_type  \\\n",
       "0      in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1      why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2      @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "3      @jason_gio meh. :p  thanks for the heads up, b...  not_cyberbullying   \n",
       "4      @rudhoeenglish this is an isis account pretend...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  black ppl aren't expected to do anything, depe...          ethnicity   \n",
       "47688  turner did not withhold his disappointment. tu...          ethnicity   \n",
       "47689  i swear to god. this dumb nigger bitch. i have...          ethnicity   \n",
       "47690  yea fuck you rt @therealexel: if youre a nigge...          ethnicity   \n",
       "47691  bro. u gotta chill rt @chillshrammy: dog fuck ...          ethnicity   \n",
       "\n",
       "0      num_hashtags  num_mentions  \\\n",
       "0                 2             0   \n",
       "1                10             0   \n",
       "2                 0             1   \n",
       "3                 0             1   \n",
       "4                 0             1   \n",
       "...             ...           ...   \n",
       "47687             0             0   \n",
       "47688             0             0   \n",
       "47689             0             0   \n",
       "47690             0             1   \n",
       "47691             0             1   \n",
       "\n",
       "0                                               hashtags           mentions  \\\n",
       "0                                   [#katandandre, #mkr]                 []   \n",
       "1      [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                     []  [@xochitlsuckkks]   \n",
       "3                                                     []       [@jason_gio]   \n",
       "4                                                     []   [@rudhoeenglish]   \n",
       "...                                                  ...                ...   \n",
       "47687                                                 []                 []   \n",
       "47688                                                 []                 []   \n",
       "47689                                                 []                 []   \n",
       "47690                                                 []     [@therealexel]   \n",
       "47691                                                 []    [@chillshrammy]   \n",
       "\n",
       "0                                              sentences  \n",
       "0      [in other words #katandandre, your food was cr...  \n",
       "1      [why is #aussietv so white?, #mkr #theblock #i...  \n",
       "2      [@xochitlsuckkks a classy whore?, or more red ...  \n",
       "3      [@jason_gio meh., :p  thanks for the heads up,...  \n",
       "4      [@rudhoeenglish this is an isis account preten...  \n",
       "...                                                  ...  \n",
       "47687  [black ppl aren't expected to do anything, dep...  \n",
       "47688  [turner did not withhold his disappointment., ...  \n",
       "47689  [i swear to god., this dumb nigger bitch., i h...  \n",
       "47690  [yea fuck you rt @therealexel: if youre a nigg...  \n",
       "47691  [bro., u gotta chill rt @chillshrammy: dog fuc...  \n",
       "\n",
       "[47656 rows x 7 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing numbers with blank\n",
    "def num_to_text(tweet):\n",
    "  for i in df:\n",
    "    if i.isdigit():\n",
    "      tweet=tweet.replace(i,'')\n",
    "  return tweet\n",
    "\n",
    "num_to_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "eXYcrZNrpJ_X",
    "outputId": "10c83af6-850d-4920-f54f-803387b4dec9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, #katandandre,, your, food, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, #aussietv, so, white?, #mkr, #theblo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "      <td>[@xochitlsuckkks, a, classy, whore?, or, more,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "\n",
       "0                                           hashtags           mentions  \\\n",
       "0                               [#katandandre, #mkr]                 []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                 []  [@xochitlsuckkks]   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "2  [@xochitlsuckkks a classy whore?, or more red ...   \n",
       "\n",
       "0                                              words  \n",
       "0  [in, other, words, #katandandre,, your, food, ...  \n",
       "1  [why, is, #aussietv, so, white?, #mkr, #theblo...  \n",
       "2  [@xochitlsuckkks, a, classy, whore?, or, more,...  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "df['words']=df['tweet_text'].apply(lambda x:x.split())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "KjbXQg-5p9LP",
    "outputId": "fcbc17ab-638d-439f-da99-33319c583456"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "\n",
       "0                                           hashtags           mentions  \\\n",
       "0                               [#katandandre, #mkr]                 []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                 []  [@xochitlsuckkks]   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "2  [@xochitlsuckkks a classy whore?, or more red ...   \n",
       "\n",
       "0                                              words  \n",
       "0  [in, other, words, katandandre, your, food, wa...  \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...  \n",
       "2  [xochitlsuckkks, a, classy, whore, or, more, r...  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing special chars\n",
    "import re\n",
    "df['words'] = df['tweet_text'].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dealing with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2id8V2gqfnU",
    "outputId": "5d731d86-0bc7-4d18-e16d-9bf489c06d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "Gn-dA1lmVryE"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "8KebH8wig36h"
   },
   "outputs": [],
   "source": [
    "# Define stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stopwords from the 'words' column\n",
    "df['words_without_stopwords'] = df['words'].apply(lambda tokens: [word for word in tokens if word not in stopwords_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "XIKXms1ThBhH",
    "outputId": "fa43861a-2a0d-4722-b260-b577a0a53dff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>words_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[words, katandandre, food, crapilicious, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "\n",
       "0                                           hashtags           mentions  \\\n",
       "0                               [#katandandre, #mkr]                 []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                 []  [@xochitlsuckkks]   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "2  [@xochitlsuckkks a classy whore?, or more red ...   \n",
       "\n",
       "0                                              words  \\\n",
       "0  [in, other, words, katandandre, your, food, wa...   \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "2  [xochitlsuckkks, a, classy, whore, or, more, r...   \n",
       "\n",
       "0                            words_without_stopwords  \n",
       "0      [words, katandandre, food, crapilicious, mkr]  \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...  \n",
       "2  [xochitlsuckkks, classy, whore, red, velvet, c...  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUFBBCmDiDwO",
    "outputId": "035f5b51-35ba-40d6-d7c5-f4885b1beee2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "id": "X3NrySm6ihEy"
   },
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "df['words_new']=df['words_without_stopwords'].apply(lambda x:[lemmatizer.lemmatize(word)for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qs-oGNAY0oVA",
    "outputId": "cebb35fc-0547-4bcf-c64e-707b187c9817"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\anush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "8DEzrqpOmmLY"
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "# Function to tokenize and tag POS\n",
    "def pos_tagging(text):\n",
    "    tokens = word_tokenize(text)  # Tokenize text\n",
    "    tagged_tokens = pos_tag(tokens)  # Tag POS\n",
    "    return tagged_tokens\n",
    "\n",
    "# Apply POS tagging to the 'tweet_text' column\n",
    "df['tweet_text_POS'] = df['tweet_text'].apply(pos_tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_lD8e8P-KmD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "h5Z2vZcTCOEJ",
    "outputId": "52e65f67-0e61-43e5-cde1-dbb2f5dd8df3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>words_without_stopwords</th>\n",
       "      <th>words_new</th>\n",
       "      <th>tweet_text_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[words, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[word, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[(in, IN), (other, JJ), (words, NNS), (#, #), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "      <td>[(@, NN), (xochitlsuckkks, VBZ), (a, DT), (cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "\n",
       "0                                           hashtags           mentions  \\\n",
       "0                               [#katandandre, #mkr]                 []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                 []  [@xochitlsuckkks]   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "2  [@xochitlsuckkks a classy whore?, or more red ...   \n",
       "\n",
       "0                                              words  \\\n",
       "0  [in, other, words, katandandre, your, food, wa...   \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "2  [xochitlsuckkks, a, classy, whore, or, more, r...   \n",
       "\n",
       "0                            words_without_stopwords  \\\n",
       "0      [words, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "2  [xochitlsuckkks, classy, whore, red, velvet, c...   \n",
       "\n",
       "0                                          words_new  \\\n",
       "0       [word, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "2  [xochitlsuckkks, classy, whore, red, velvet, c...   \n",
       "\n",
       "0                                     tweet_text_POS  \n",
       "0  [(in, IN), (other, JJ), (words, NNS), (#, #), ...  \n",
       "1  [(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...  \n",
       "2  [(@, NN), (xochitlsuckkks, VBZ), (a, DT), (cla...  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Fj0fcE3L_S4x",
    "outputId": "ed8e1f34-6adc-4b8a-c8e2-0e83dd2902c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>words_without_stopwords</th>\n",
       "      <th>words_new</th>\n",
       "      <th>tweet_text_POS</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>i swear to god. this dumb nigger bitch. i have...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i swear to god., this dumb nigger bitch., i h...</td>\n",
       "      <td>[i, swear, to, god, this, dumb, nigger, bitch,...</td>\n",
       "      <td>[swear, god, dumb, nigger, bitch, got, bleach,...</td>\n",
       "      <td>[swear, god, dumb, nigger, bitch, got, bleach,...</td>\n",
       "      <td>[(i, NN), (swear, VBP), (to, TO), (god, VB), (...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>yea fuck you rt @therealexel: if youre a nigge...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@therealexel]</td>\n",
       "      <td>[yea fuck you rt @therealexel: if youre a nigg...</td>\n",
       "      <td>[yea, fuck, you, rt, therealexel, if, youre, a...</td>\n",
       "      <td>[yea, fuck, rt, therealexel, youre, nigger, fu...</td>\n",
       "      <td>[yea, fuck, rt, therealexel, youre, nigger, fu...</td>\n",
       "      <td>[(yea, RB), (fuck, NN), (you, PRP), (rt, VBP),...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>bro. u gotta chill rt @chillshrammy: dog fuck ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@chillshrammy]</td>\n",
       "      <td>[bro., u gotta chill rt @chillshrammy: dog fuc...</td>\n",
       "      <td>[bro, u, gotta, chill, rt, chillshrammy, dog, ...</td>\n",
       "      <td>[bro, u, gotta, chill, rt, chillshrammy, dog, ...</td>\n",
       "      <td>[bro, u, gotta, chill, rt, chillshrammy, dog, ...</td>\n",
       "      <td>[(bro, NN), (., .), (u, JJ), (got, VBD), (ta, ...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                             tweet_text cyberbullying_type  \\\n",
       "47689  i swear to god. this dumb nigger bitch. i have...          ethnicity   \n",
       "47690  yea fuck you rt @therealexel: if youre a nigge...          ethnicity   \n",
       "47691  bro. u gotta chill rt @chillshrammy: dog fuck ...          ethnicity   \n",
       "\n",
       "0      num_hashtags  num_mentions hashtags         mentions  \\\n",
       "47689             0             0       []               []   \n",
       "47690             0             1       []   [@therealexel]   \n",
       "47691             0             1       []  [@chillshrammy]   \n",
       "\n",
       "0                                              sentences  \\\n",
       "47689  [i swear to god., this dumb nigger bitch., i h...   \n",
       "47690  [yea fuck you rt @therealexel: if youre a nigg...   \n",
       "47691  [bro., u gotta chill rt @chillshrammy: dog fuc...   \n",
       "\n",
       "0                                                  words  \\\n",
       "47689  [i, swear, to, god, this, dumb, nigger, bitch,...   \n",
       "47690  [yea, fuck, you, rt, therealexel, if, youre, a...   \n",
       "47691  [bro, u, gotta, chill, rt, chillshrammy, dog, ...   \n",
       "\n",
       "0                                words_without_stopwords  \\\n",
       "47689  [swear, god, dumb, nigger, bitch, got, bleach,...   \n",
       "47690  [yea, fuck, rt, therealexel, youre, nigger, fu...   \n",
       "47691  [bro, u, gotta, chill, rt, chillshrammy, dog, ...   \n",
       "\n",
       "0                                              words_new  \\\n",
       "47689  [swear, god, dumb, nigger, bitch, got, bleach,...   \n",
       "47690  [yea, fuck, rt, therealexel, youre, nigger, fu...   \n",
       "47691  [bro, u, gotta, chill, rt, chillshrammy, dog, ...   \n",
       "\n",
       "0                                         tweet_text_POS  tweet_length  \n",
       "47689  [(i, NN), (swear, VBP), (to, TO), (god, VB), (...           104  \n",
       "47690  [(yea, RB), (fuck, NN), (you, PRP), (rt, VBP),...            90  \n",
       "47691  [(bro, NN), (., .), (u, JJ), (got, VBD), (ta, ...            76  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_length'] = df['tweet_text'].apply(len)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jynuiJH7oevQ"
   },
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cbx3rSnonI7X",
    "outputId": "f303b753-1e96-47e7-c605-d989de1c5166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\anush\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\anush\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "#WORD2VEC\n",
    "\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "jZ5OR1t2oyZP"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mP6QXgSwpBBL",
    "outputId": "917ae450-cdee-495a-a7f2-b2682be4d6ea"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "aedPJkC859IL"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train Skip-gram Model\n",
    "skipgram_model = Word2Vec(\n",
    "    sentences=df['words_without_stopwords'],  # Use preprocessed words\n",
    "    vector_size=100,  # Vector dimension\n",
    "    window=5,\n",
    "    sg=1,  # Skip-gram\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Function to get average word vectors for each tweet\n",
    "def get_avg_word_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Apply average word vector transformation\n",
    "df['tweet_vector'] = df['words_without_stopwords'].apply(lambda x: get_avg_word_vector(x, skipgram_model))\n",
    "\n",
    "# Convert list of vectors into a DataFrame\n",
    "tweet_vector_df = pd.DataFrame(df['tweet_vector'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "D07umc8i7eP8"
   },
   "outputs": [],
   "source": [
    "# Select numeric features\n",
    "numeric_features = df[['num_hashtags', 'num_mentions', 'tweet_length']]\n",
    "\n",
    "# Combine numeric and text vector features\n",
    "\n",
    "\n",
    "X_combined = pd.concat([numeric_features.reset_index(drop=True), tweet_vector_df.reset_index(drop=True)], axis=1)\n",
    "y = df['cyberbullying_type']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "NXj73f2576pQ",
    "outputId": "de087579-2165-4970-e72b-1982e72846ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>words_without_stopwords</th>\n",
       "      <th>words_new</th>\n",
       "      <th>tweet_text_POS</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[words, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[word, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[(in, IN), (other, JJ), (words, NNS), (#, #), ...</td>\n",
       "      <td>61</td>\n",
       "      <td>[-0.19821869, -0.16141829, 0.45322648, -0.4486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...</td>\n",
       "      <td>115</td>\n",
       "      <td>[-0.14349976, -0.15604629, 0.2932265, -0.14223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@xochitlsuckkks]</td>\n",
       "      <td>[@xochitlsuckkks a classy whore?, or more red ...</td>\n",
       "      <td>[xochitlsuckkks, a, classy, whore, or, more, r...</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "      <td>[(@, NN), (xochitlsuckkks, VBZ), (a, DT), (cla...</td>\n",
       "      <td>60</td>\n",
       "      <td>[-0.11901531, -0.12100335, 0.3366897, 0.076935...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "2             0             1   \n",
       "\n",
       "0                                           hashtags           mentions  \\\n",
       "0                               [#katandandre, #mkr]                 []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...                 []   \n",
       "2                                                 []  [@xochitlsuckkks]   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "2  [@xochitlsuckkks a classy whore?, or more red ...   \n",
       "\n",
       "0                                              words  \\\n",
       "0  [in, other, words, katandandre, your, food, wa...   \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "2  [xochitlsuckkks, a, classy, whore, or, more, r...   \n",
       "\n",
       "0                            words_without_stopwords  \\\n",
       "0      [words, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "2  [xochitlsuckkks, classy, whore, red, velvet, c...   \n",
       "\n",
       "0                                          words_new  \\\n",
       "0       [word, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "2  [xochitlsuckkks, classy, whore, red, velvet, c...   \n",
       "\n",
       "0                                     tweet_text_POS  tweet_length  \\\n",
       "0  [(in, IN), (other, JJ), (words, NNS), (#, #), ...            61   \n",
       "1  [(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...           115   \n",
       "2  [(@, NN), (xochitlsuckkks, VBZ), (a, DT), (cla...            60   \n",
       "\n",
       "0                                       tweet_vector  \n",
       "0  [-0.19821869, -0.16141829, 0.45322648, -0.4486...  \n",
       "1  [-0.14349976, -0.15604629, 0.2932265, -0.14223...  \n",
       "2  [-0.11901531, -0.12100335, 0.3366897, 0.076935...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "aEqjIQIf8JAk"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extract features and target\n",
    "X = np.array(df['tweet_vector'].tolist())  # Convert list of vectors to a NumPy array\n",
    "y = df['cyberbullying_type']\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "SPjcJf1p8mS1"
   },
   "outputs": [],
   "source": [
    "# Reshape input data to 3D: (samples, timesteps, features)\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "5dIyHECZ8piy",
    "outputId": "2dc74dc4-9476-49a8-9eee-672661fff401"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,224\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              â”‚           \u001b[38;5;34m198\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,502</span> (25.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,502\u001b[0m (25.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,502</span> (25.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,502\u001b[0m (25.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Input\n",
    "\n",
    "# Build RNN Model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_rnn.shape[1], 1)),  # Updated input shape\n",
    "    SimpleRNN(64, activation='tanh', return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ku9xv7qN8upM",
    "outputId": "6ecd8670-1573-49fb-b2c2-742852359b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.4901 - loss: 1.2994 - val_accuracy: 0.7051 - val_loss: 0.7761\n",
      "Epoch 2/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.6821 - loss: 0.8553 - val_accuracy: 0.7462 - val_loss: 0.6696\n",
      "Epoch 3/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7106 - loss: 0.7770 - val_accuracy: 0.7518 - val_loss: 0.6131\n",
      "Epoch 4/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7209 - loss: 0.7535 - val_accuracy: 0.7483 - val_loss: 0.6647\n",
      "Epoch 5/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7271 - loss: 0.7372 - val_accuracy: 0.7655 - val_loss: 0.6084\n",
      "Epoch 6/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7306 - loss: 0.7252 - val_accuracy: 0.7515 - val_loss: 0.6317\n",
      "Epoch 7/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.7413 - loss: 0.6972 - val_accuracy: 0.7719 - val_loss: 0.5762\n",
      "Epoch 8/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7451 - loss: 0.6915 - val_accuracy: 0.7695 - val_loss: 0.6230\n",
      "Epoch 9/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7436 - loss: 0.6891 - val_accuracy: 0.7606 - val_loss: 0.6171\n",
      "Epoch 10/10\n",
      "\u001b[1m1192/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7472 - loss: 0.6883 - val_accuracy: 0.7708 - val_loss: 0.5838\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_rnn, y_train,\n",
    "    validation_data=(X_test_rnn, y_test),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-6Z7kRz-bYa",
    "outputId": "67c16c3a-35c1-42a1-d85f-c0f08a22d3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (38124, 100, 1)\n",
      "Testing Data Shape: (9532, 100, 1)\n",
      "Labels Shape: (38124,) (9532,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape:\", X_train_rnn.shape)  # Should be (samples, 128, 1)\n",
    "print(\"Testing Data Shape:\", X_test_rnn.shape)    # Should be (samples, 128, 1)\n",
    "print(\"Labels Shape:\", y_train.shape, y_test.shape)  # Should match number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cl5CLeNpDa8B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmmOALbp86Bt",
    "outputId": "b17197cf-4a0e-4cd3-8fa9-a12396b05ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                age       0.88      0.97      0.93      1602\n",
      "          ethnicity       0.94      0.94      0.94      1636\n",
      "             gender       0.85      0.75      0.80      1514\n",
      "  not_cyberbullying       0.51      0.52      0.52      1624\n",
      "other_cyberbullying       0.57      0.49      0.53      1594\n",
      "           religion       0.83      0.95      0.89      1562\n",
      "\n",
      "           accuracy                           0.77      9532\n",
      "          macro avg       0.77      0.77      0.77      9532\n",
      "       weighted avg       0.77      0.77      0.77      9532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "ZeMoNJWcIsvy",
    "outputId": "7c003f35-e0fb-4eb3-8118-78a45a5a1038"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>words_without_stopwords</th>\n",
       "      <th>words_new</th>\n",
       "      <th>tweet_text_POS</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>tweet_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[#katandandre, #mkr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[in other words #katandandre, your food was cr...</td>\n",
       "      <td>[in, other, words, katandandre, your, food, wa...</td>\n",
       "      <td>[words, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[word, katandandre, food, crapilicious, mkr]</td>\n",
       "      <td>[(in, IN), (other, JJ), (words, NNS), (#, #), ...</td>\n",
       "      <td>61</td>\n",
       "      <td>[-0.19821869, -0.16141829, 0.45322648, -0.4486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>[#aussietv, #mkr, #theblock, #imacelebrityau, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[why is #aussietv so white?, #mkr #theblock #i...</td>\n",
       "      <td>[why, is, aussietv, so, white, mkr, theblock, ...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>[(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...</td>\n",
       "      <td>115</td>\n",
       "      <td>[-0.14349976, -0.15604629, 0.2932265, -0.14223...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                         tweet_text cyberbullying_type  \\\n",
       "0  in other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying   \n",
       "\n",
       "0  num_hashtags  num_mentions  \\\n",
       "0             2             0   \n",
       "1            10             0   \n",
       "\n",
       "0                                           hashtags mentions  \\\n",
       "0                               [#katandandre, #mkr]       []   \n",
       "1  [#aussietv, #mkr, #theblock, #imacelebrityau, ...       []   \n",
       "\n",
       "0                                          sentences  \\\n",
       "0  [in other words #katandandre, your food was cr...   \n",
       "1  [why is #aussietv so white?, #mkr #theblock #i...   \n",
       "\n",
       "0                                              words  \\\n",
       "0  [in, other, words, katandandre, your, food, wa...   \n",
       "1  [why, is, aussietv, so, white, mkr, theblock, ...   \n",
       "\n",
       "0                            words_without_stopwords  \\\n",
       "0      [words, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "\n",
       "0                                          words_new  \\\n",
       "0       [word, katandandre, food, crapilicious, mkr]   \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...   \n",
       "\n",
       "0                                     tweet_text_POS  tweet_length  \\\n",
       "0  [(in, IN), (other, JJ), (words, NNS), (#, #), ...            61   \n",
       "1  [(why, WRB), (is, VBZ), (#, #), (aussietv, RB)...           115   \n",
       "\n",
       "0                                       tweet_vector  \n",
       "0  [-0.19821869, -0.16141829, 0.45322648, -0.4486...  \n",
       "1  [-0.14349976, -0.15604629, 0.2932265, -0.14223...  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93      1602\n",
      "           1       0.94      0.94      0.94      1636\n",
      "           2       0.85      0.75      0.80      1514\n",
      "           3       0.51      0.52      0.52      1624\n",
      "           4       0.57      0.49      0.53      1594\n",
      "           5       0.83      0.95      0.89      1562\n",
      "\n",
      "    accuracy                           0.77      9532\n",
      "   macro avg       0.77      0.77      0.77      9532\n",
      "weighted avg       0.77      0.77      0.77      9532\n",
      "\n",
      "[[1556    8    2   13   17    6]\n",
      " [   3 1543   14    4   43   29]\n",
      " [   7   20 1128  237   92   30]\n",
      " [ 110   24   67  845  423  155]\n",
      " [  80   46   93  502  787   86]\n",
      " [   3    2   16   45    8 1488]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to class labels\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "print(confusion_matrix(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
